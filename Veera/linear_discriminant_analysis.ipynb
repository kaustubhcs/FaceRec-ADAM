{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and displaying an image\n",
    "# from PIL import Image\n",
    "# img = Image.open('/home/dvveera/db/orl/s1/1.pgm')\n",
    "# print(img.format, img.size, img.mode)\n",
    "# display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned Labels to Training, Validation and Test Data\n",
      "Train data: 20/240\n",
      "Train data: 40/240\n",
      "Train data: 60/240\n",
      "Train data: 80/240\n",
      "Train data: 100/240\n",
      "Train data: 120/240\n",
      "Train data: 140/240\n",
      "Train data: 160/240\n",
      "Train data: 180/240\n",
      "Train data: 200/240\n",
      "Train data: 220/240\n",
      "Valid data: 20/80\n",
      "Valid data: 40/80\n",
      "Valid data: 60/80\n",
      "Test data: 20/80\n",
      "Test data: 40/80\n",
      "Test data: 60/80\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import load_dataset\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "dir_src = '/home/dvveera/dvveera_hdd2tb/orl'\n",
    "data_label = load_dataset.load_data_label(dir_src)\n",
    "\n",
    "# Training, validation and test data with labels\n",
    "# data_label = list(train, valid, test, mean_train)\n",
    "train_storage, train_labels = zip(*data_label[0])\n",
    "valid_storage, valid_labels = zip(*data_label[1])\n",
    "test_storage, test_labels = zip(*data_label[2])\n",
    "mean_storage = data_label[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample set and labels\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# train_storage = []\n",
    "# train_storage.append(np.array([[196, 35, 234], [232, 59, 244], [243, 57, 226]]))\n",
    "# train_storage.append(np.array([[188, 15, 236], [244, 44, 228], [251, 48, 230]]))\n",
    "# train_storage.append(np.array([[246, 48, 222], [225, 40, 226], [208, 35, 234]]))\n",
    "# train_storage.append(np.array([[208, 16, 235], [255, 44, 229], [236, 34, 247]]))\n",
    "# train_storage.append(np.array([[245, 21, 213], [254, 55, 252], [215, 51, 249]]))\n",
    "# train_storage.append(np.array([[248, 22, 225], [252, 30, 240], [242, 27, 244]]))\n",
    "# train_storage.append(np.array([[255, 223, 224], [255, 0, 255], [249, 255, 235]]))\n",
    "# train_storage.append(np.array([[234, 255, 205], [251, 0, 251], [238, 253, 240]]))\n",
    "# train_storage.append(np.array([[232, 255, 231], [247, 38, 246], [190, 236, 250]]))\n",
    "# train_storage.append(np.array([[255, 241, 208], [255, 28, 255], [194, 234, 188]]))\n",
    "# train_storage.append(np.array([[237, 243, 237], [237, 19, 251], [227, 225, 237]]))\n",
    "# train_storage.append(np.array([[224, 251, 215], [245, 31, 222], [233, 255, 254]]))\n",
    "# train_labels = [2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]\n",
    "# for i in train_storage:\n",
    "#     dis1 = Image.fromarray(np.transpose(np.uint8(i)))\n",
    "#     dis1 = dis1.resize((100, 100))\n",
    "#     display(dis1)\n",
    "# print(train_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.82 ms, sys: 192 µs, total: 6.01 ms\n",
      "Wall time: 5.87 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Linear Discriminant Analysis\n",
    "from collections import Counter\n",
    "# Converting images to a one-dimensional vector\n",
    "train_1d = [t.flatten() for t in train_storage]\n",
    "# Calculate the mean of images in each class\n",
    "label_dict = Counter(train_labels)\n",
    "mean = {}\n",
    "for idx, t in enumerate(train_1d):\n",
    "    lab = train_labels[idx]\n",
    "    if lab not in mean:\n",
    "        mean[lab] = t / label_dict[lab]\n",
    "    else:\n",
    "        mean[lab] += t / label_dict[lab]\n",
    "# print('Calculated the means of the images in each class')\n",
    "# print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated the in-class scatter matrix\n",
      "CPU times: user 36.2 s, sys: 40.4 s, total: 1min 16s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate in class scatter matrix\n",
    "Sw = []\n",
    "for idx, t in enumerate(train_1d):\n",
    "    lab = train_labels[idx]\n",
    "    if idx == 0:\n",
    "        Sw = np.outer(t - mean[lab], t - mean[lab])\n",
    "    else:\n",
    "        Sw += np.outer(t - mean[lab], t - mean[lab])\n",
    "print('Calculated the in-class scatter matrix')\n",
    "# print(Sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated the between-class scatter matrix\n",
      "CPU times: user 9.26 s, sys: 12.8 s, total: 22.1 s\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate between class scatter matrix\n",
    "# Calculate the mean of all images\n",
    "mean_all = np.sum(train_1d, axis = 0) / len(train_1d)\n",
    "# Calculate between class scatter matrix\n",
    "for idx, m in enumerate(mean):\n",
    "    if idx == 0:\n",
    "        Sb = label_dict[m] * np.outer(mean[m] - mean_all, mean[m] - mean_all)\n",
    "    else:\n",
    "        Sb += label_dict[m] * np.outer(mean[m] - mean_all, mean[m] - mean_all)\n",
    "print('Calculated the between-class scatter matrix')\n",
    "# print(Sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 26s, sys: 1.98 s, total: 5min 28s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Compute the generalized eigen values and eigen vectors\n",
    "A = np.dot(np.linalg.inv(Sw), Sb)\n",
    "eig_values, eig_vectors = np.linalg.eigh(A)\n",
    "# print(eig_values)\n",
    "# print(mean_all)\n",
    "# print(mean)\n",
    "eig = list(zip(eig_values, np.transpose(eig_vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted eigen values and eigen vectors from high to low\n",
      "CPU times: user 765 µs, sys: 113 µs, total: 878 µs\n",
      "Wall time: 877 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sort eigenvalues and eigenvectors\n",
    "eig = sorted(eig, key=lambda x: x[0], reverse = True)\n",
    "print('Sorted eigen values and eigen vectors from high to low')\n",
    "# print(eig)\n",
    "# temp = eig_values\n",
    "# sorted(temp, reverse = True)\n",
    "# print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected the first C - 1 eigenvectors\n",
      "CPU times: user 14.2 ms, sys: 4.32 ms, total: 18.5 ms\n",
      "Wall time: 18.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Select the first C - 1 eigen vectors\n",
    "eig_values, eig_vectors = zip(*eig)\n",
    "new_eig = []\n",
    "for idx, e in enumerate(eig):\n",
    "    if idx < (len(label_dict) - 1):\n",
    "        new_eig.append(e)\n",
    "print('Selected the first C - 1 eigenvectors')\n",
    "# print(new_eig)\n",
    "eig_values, eig_vectors = zip(*new_eig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select specified number of eigenvectors\n",
    "# n_eig = int(np.ceil(0.01 * len(new_eig)))\n",
    "# temp_values = []\n",
    "# temp_vectors = []\n",
    "# for i in range(n_eig):\n",
    "#     temp_values.append(eig_values[i])\n",
    "#     temp_vectors.append(eig_vectors[i])\n",
    "# eig_values, eig_vectors = temp_values, temp_vectors\n",
    "# print(len(eig_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove last 40% of eigenvectors\n",
    "# n_eig = int(np.ceil(0.6 * len(eig_values)))\n",
    "# temp_values = []\n",
    "# temp_vectors = []\n",
    "# for i in range(n_eig):\n",
    "#     temp_values.append(eig_values[i])\n",
    "#     temp_vectors.append(eig_vectors[i])\n",
    "# eig_values, eig_vectors = temp_values, temp_vectors\n",
    "# print(len(eig_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select eigenvectors based on energy\n",
    "# threshold = 0.9\n",
    "# sum_eig = np.sum(eig_values)\n",
    "# temp_values = []\n",
    "# temp_vectors = []\n",
    "# sum_e = 0\n",
    "# for e in eig_values:\n",
    "#     if (sum_e / sum_eig) > threshold:\n",
    "#         break\n",
    "#     else:\n",
    "#         temp_values.append(e)\n",
    "#         idx = eig_values.index(e)\n",
    "#         temp_vectors.append(eig_vectors[idx])\n",
    "#     sum_e += e\n",
    "# eig_values, eig_vectors = temp_values, temp_vectors\n",
    "# print(len(eig_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select eigenvectors based on stretching\n",
    "# threshold = 0.01\n",
    "# largest_eig = eig_values[0]\n",
    "# temp_values = []\n",
    "# temp_vectors = []\n",
    "# for e in eig_values:\n",
    "#     if (e / largest_eig) < threshold:\n",
    "#         break\n",
    "#     else:\n",
    "#         temp_values.append(e)\n",
    "#         idx = eig_values.index(e)\n",
    "#         temp_vectors.append(eig_vectors[idx])\n",
    "# eig_values, eig_vectors = temp_values, temp_vectors\n",
    "# print(len(eig_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove the first eigenvector\n",
    "# temp_values = []\n",
    "# temp_vectors = []\n",
    "# first_eig = eig_values[0]\n",
    "# for e in eig_values:\n",
    "#     if e == first_eig:\n",
    "#         pass\n",
    "#     else:\n",
    "#         temp_values.append(e)\n",
    "#         idx = eig_values.index(e)\n",
    "#         temp_vectors.append(eig_vectors[idx])\n",
    "# eig_values, eig_vectors = temp_values, temp_vectors\n",
    "# print(len(eig_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.94 ms, sys: 139 µs, total: 5.08 ms\n",
      "Wall time: 4.51 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create projection matrix\n",
    "# eig_values, eig_vectors = zip(*new_eig)\n",
    "V = np.transpose(eig_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 ms, sys: 9.5 ms, total: 23.8 ms\n",
      "Wall time: 14 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Project training images into subspace\n",
    "data_matrix = np.transpose(train_1d)\n",
    "proj_data_matrix = np.dot(eig_vectors, data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.53 ms, sys: 4.23 ms, total: 9.76 ms\n",
      "Wall time: 7.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Identify test images\n",
    "valid_1d = [t.flatten() for t in valid_storage]\n",
    "# Create data matrix\n",
    "valid_data_matrix = np.transpose(valid_1d)\n",
    "# Project test images into the same subspace as training images\n",
    "proj_valid_matrix = np.dot(eig_vectors, valid_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 123 ms, sys: 17.8 ms, total: 141 ms\n",
      "Wall time: 95.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate L2 norms\n",
    "tr1 = np.transpose(proj_valid_matrix)\n",
    "tr2 = np.transpose(proj_data_matrix)\n",
    "l2 = []\n",
    "for a in tr1:\n",
    "    l1 = [np.linalg.norm(a - b) for b in tr2]\n",
    "    l2.append(l1)\n",
    "# Find the index of the training image that matches closely with the test image\n",
    "idx = [l.index(min(l)) for l in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate L1 norms\n",
    "# tr1 = np.transpose(proj_valid_matrix)\n",
    "# tr2 = np.transpose(proj_data_matrix)\n",
    "# l2 = []\n",
    "# for a in tr1:\n",
    "#     l1 = [np.sum(abs(a - b)) for b in tr2]\n",
    "#     l2.append(l1)\n",
    "# # Find the index of the training image that matches closely with the test image\n",
    "# idx = [l.index(min(l)) for l in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate covariance measure\n",
    "# tr1 = np.transpose(proj_valid_matrix)\n",
    "# tr2 = np.transpose(proj_data_matrix)\n",
    "# l2 = []\n",
    "# for a in tr1:\n",
    "#     l1 = [ - np.dot(a / np.linalg.norm(a), b / np.linalg.norm(b)) for b in tr2]\n",
    "#     l2.append(l1)\n",
    "# # Find the index of the training image that matches closely with the test image\n",
    "# idx = [l.index(min(l)) for l in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate mahalanobis distance between two image vectors\n",
    "def mah(x, y):\n",
    "    m = 0\n",
    "    for i in range(len(x)):\n",
    "        m += x[i] * y[i] * 1 / np.sqrt(eig_values[i])\n",
    "    return -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate mahalanobis\n",
    "# tr1 = np.transpose(proj_valid_matrix)\n",
    "# tr2 = np.transpose(proj_data_matrix)\n",
    "# l2 = []\n",
    "# for a in tr1:\n",
    "#     l1 = [mah(a, b) for b in tr2]\n",
    "#     l2.append(l1)\n",
    "# # Find the index of the training image that matches closely with the test image\n",
    "# idx = [l.index(min(l)) for l in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate correlation between two image vectors\n",
    "def corr(x, y):\n",
    "    mean_x = np.mean(x)\n",
    "    mean_y = np.mean(y)\n",
    "    std_x = np.std(x, ddof = 1)\n",
    "    std_y = np.std(y, ddof = 1)\n",
    "    m = 0\n",
    "    for i in range(len(x)):\n",
    "        m += (x[i] - mean_x) * (y[i] - mean_y) / (std_x * std_y)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate correlation\n",
    "# tr1 = np.transpose(proj_valid_matrix)\n",
    "# tr2 = np.transpose(proj_data_matrix)\n",
    "# l2 = []\n",
    "# for a in tr1:\n",
    "#     l1 = [corr(a, b) for b in tr2]\n",
    "#     l2.append(l1)\n",
    "# # Find the index of the training image that matches closely with the test image\n",
    "# idx = [l.index(max(l)) for l in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 1e+03 ns, total: 12 µs\n",
      "Wall time: 13.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Find the label for the test images\n",
    "out = []\n",
    "for i in idx:\n",
    "    out.append(train_labels[i])\n",
    "# print(list(zip(out, idx)))\n",
    "# print(list(zip(valid_labels, idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(%): 96.25\n",
      "CPU times: user 325 µs, sys: 48 µs, total: 373 µs\n",
      "Wall time: 238 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Find the accuracy\n",
    "correct = 0\n",
    "for i in range(len(out)):\n",
    "    if out[i] == valid_labels[i]:\n",
    "        correct += 1\n",
    "accuracy = correct * 100 / len(out)\n",
    "print('Accuracy(%): ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify test images\n",
    "test_1d = [t.flatten() for t in test_storage]\n",
    "# Create data matrix\n",
    "test_data_matrix = np.transpose(test_1d)\n",
    "# Project test images into the same subspace as training images\n",
    "proj_test_matrix = np.dot(eig_vectors, test_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate L2 norms\n",
    "tr1 = np.transpose(proj_test_matrix)\n",
    "tr2 = np.transpose(proj_data_matrix)\n",
    "l2 = []\n",
    "for a in tr1:\n",
    "    l1 = [np.linalg.norm(a - b) for b in tr2]\n",
    "    l2.append(l1)\n",
    "# Find the index of the training image that matches closely with the test image\n",
    "idx = [l.index(min(l)) for l in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate L1 norms\n",
    "# tr1 = np.transpose(proj_valid_matrix)\n",
    "# tr2 = np.transpose(proj_data_matrix)\n",
    "# l2 = []\n",
    "# for a in tr1:\n",
    "#     l1 = [np.sum(abs(a - b)) for b in tr2]\n",
    "#     l2.append(l1)\n",
    "# # Find the index of the training image that matches closely with the test image\n",
    "# idx = [l.index(min(l)) for l in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate covariance measure\n",
    "# tr1 = np.transpose(proj_valid_matrix)\n",
    "# tr2 = np.transpose(proj_data_matrix)\n",
    "# l2 = []\n",
    "# for a in tr1:\n",
    "#     l1 = [ - np.dot(a / np.linalg.norm(a), b / np.linalg.norm(b)) for b in tr2]\n",
    "#     l2.append(l1)\n",
    "# # Find the index of the training image that matches closely with the test image\n",
    "# idx = [l.index(min(l)) for l in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate mahalanobis\n",
    "# tr1 = np.transpose(proj_valid_matrix)\n",
    "# tr2 = np.transpose(proj_data_matrix)\n",
    "# l2 = []\n",
    "# for a in tr1:\n",
    "#     l1 = [mah(a, b) for b in tr2]\n",
    "#     l2.append(l1)\n",
    "# # Find the index of the training image that matches closely with the test image\n",
    "# idx = [l.index(min(l)) for l in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate correlation\n",
    "# tr1 = np.transpose(proj_valid_matrix)\n",
    "# tr2 = np.transpose(proj_data_matrix)\n",
    "# l2 = []\n",
    "# for a in tr1:\n",
    "#     l1 = [corr(a, b) for b in tr2]\n",
    "#     l2.append(l1)\n",
    "# # Find the index of the training image that matches closely with the test image\n",
    "# idx = [l.index(max(l)) for l in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the label for the test images\n",
    "out = []\n",
    "for i in idx:\n",
    "    out.append(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the accuracy\n",
    "correct = 0\n",
    "for i in range(len(out)):\n",
    "    if out[i] == test_labels[i]:\n",
    "        correct += 1\n",
    "accuracy = correct * 100 / len(out)\n",
    "print('Accuracy(%): ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print images (true / predicted)\n",
    "# j = 0\n",
    "# for i in range(len(out)):\n",
    "#     dis1 = Image.fromarray(train_storage[idx[i]])\n",
    "#     display(dis1)\n",
    "#     print('Predicted:' + str(out[i]))\n",
    "#     dis2 = Image.fromarray(test_storage[j])\n",
    "#     display(dis2)\n",
    "#     print('True:' + str(test_labels[j]))\n",
    "#     print('-----------------------------------')\n",
    "#     j += 1\n",
    "# # print(list(zip(out, idx)))\n",
    "# # print(list(zip(test_labels, idx)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
